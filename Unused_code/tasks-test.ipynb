{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create your tasks here\n",
    "#from __future__ import absolute_import, unicode_literals\n",
    "from celery.task.schedules import crontab\n",
    "from celery.decorators import periodic_task, task\n",
    "from celery.utils.log import get_task_logger\n",
    "#from celery import shared_task\n",
    "from celery.canvas import subtask\n",
    "from celery.result import AsyncResult\n",
    "from model_engine import ModelRunnerSet\n",
    "from orm.models.htmmodel import ModelSet, HtmModel, Prediction\n",
    "from .search import getData\n",
    "import time\n",
    "#from orm.models.project import Project\n",
    "\n",
    "logger = get_task_logger(__name__)\n",
    "\n",
    "#DATETIME_FORMAT = \"%Y-%m-%dT%H:%M:%S.%fZ\"\n",
    "\n",
    "# Create your tasks here\n",
    "@periodic_task(\n",
    "    run_every=(crontab(minute='*')),\n",
    "    name=\"run_all_model_predictions\",\n",
    ")\n",
    "def run_all_model_predictions ():\n",
    "    # get all active model sets\n",
    "    active_sets = ModelSet.objects.filter(active=True).values(\"id\",\"task_id\")\n",
    "    logger.info(\"active sets: {}\".format(active_sets))\n",
    "\n",
    "    for key in active_sets:\n",
    "        if key[\"task_id\"] == \"not running\":\n",
    "            task_id = subtask('run_model_predictions', args=(key[\"id\"], )).apply_async().id\n",
    "            ModelSet.objects.filter(id=key[\"id\"]).update(task_id=task_id)\n",
    "        else:\n",
    "            logger.info(\"already running\")\n",
    "\n",
    "\n",
    "@task (name=\"run_model_predictions\")\n",
    "def run_model_predictions(modelset_id, n=None, defaultValue=0):\n",
    "    \"\"\"\n",
    "    run model predictions\n",
    "    \"\"\"\n",
    "    mset = ModelSet.objects.filter(id=modelset_id).values(\"newly_created\",\n",
    "        \"aggregation_interval\", 'project__name', 'project__identifier')\n",
    "\n",
    "    newly_created = mset[0][\"newly_created\"]\n",
    "    ival = mset[0][\"aggregation_interval\"]\n",
    "    index = '%s_%s' %(mset[0]['project__name'].replace(' ', '-').lower(),\n",
    "                                    mset[0]['project__identifier'])\n",
    "\n",
    "    logger.info(\"loading data\")\n",
    "    if newly_created:\n",
    "        data = getData(index, ival=ival)\n",
    "        ModelSet.objects.filter(id=modelset_id).update(newly_created=False)\n",
    "\n",
    "    else:\n",
    "        # Get last timestamps that have been processed\n",
    "        last_timestamps = HtmModel.objects.filter(\n",
    "            model_set_id=modelset_id).values(\"last_timestamp_processed\")\n",
    "\n",
    "        # get all data since last timestamp\n",
    "        lts = last_timestamps[0][\"last_timestamp_processed\"]\n",
    "        print lts\n",
    "        data = getData(index, timestamp=lts, ival=ival)\n",
    "\n",
    "    logger.info(\"number of input fields {}\".format(len(data[0])))\n",
    "\n",
    "    if n is None or len(data) < n:\n",
    "        n = len(data)\n",
    "    else:\n",
    "        data = data[:n]\n",
    "\n",
    "    #print \"number of data rows {}\".format(n)\n",
    "    #print data\n",
    "\n",
    "    if n>=1:\n",
    "\n",
    "        logger.info(\"running predictions\")\n",
    "        run_model_predictions.update_state(state=\"LOADING\")\n",
    "        #input_chans = data[0].keys()\n",
    "        modelrunners = ModelRunnerSet (\n",
    "            modelset_id = modelset_id,\n",
    "            pretrained = not newly_created\n",
    "            #input_chans = [x for x in input_chans if x is not \"timestamp\"]\n",
    "            )\n",
    "        predFields = modelrunners.getPredFields()\n",
    "\n",
    "        for step, row in enumerate(data):\n",
    "            #logger.info(step)\n",
    "\n",
    "            # stop_running = HtmModel.objects.filter(\n",
    "            #         model_set_id=modelset_id).values(\"stop_running\")[0][\"stop_running\"]\n",
    "            stop_running = ModelSet.objects.filter(\n",
    "                    id=modelset_id).values(\"stop_running\")[0][\"stop_running\"]\n",
    "\n",
    "            #logger.info(stop_running)\n",
    "            if stop_running:\n",
    "                break\n",
    "\n",
    "            #print \"PROCESSING {}%\".format(step*float(100)/n)\n",
    "            #if (step % 1000) == 0 and step>0:\n",
    "            if ((step+1) % 1000) == 0:\n",
    "                logger.info('no. of rows processed: {}'.format(step))\n",
    "                run_model_predictions.update_state(state=\"SAVING\")\n",
    "                modelrunners.save()\n",
    "\n",
    "            run_model_predictions.update_state(state=\"PROCESSING {}%\".format(step*float(100)/n))\n",
    "\n",
    "            for field in predFields:\n",
    "                if field not in row:\n",
    "                    row[field]=defaultValue\n",
    "            modelrunners.run(row)\n",
    "\n",
    "        run_model_predictions.update_state(state=\"SAVING\")\n",
    "        #save models\n",
    "        modelrunners.save()\n",
    "        # Allow to start predictions again\n",
    "        ModelSet.objects.filter(id=modelset_id).update(stop_running=False)\n",
    "        run_model_predictions.update_state(state=\"SUCCESS\")\n",
    "        ModelSet.objects.filter(id=modelset_id).update(task_id=\"not running\")\n",
    "\n",
    "    return 'finished model predictions'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
