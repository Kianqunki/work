{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from matplotlib import pyplot\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pylab as plt\n",
    "import SimAnomalyDataset as sim\n",
    "import evaluatePredictionError as evalPred\n",
    "\n",
    "\"\"\"\n",
    "Main code of LSTM anomaly detection, including data preparation\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# transform series into train and test sets for supervised learning\n",
    "def prepare_data(series, n_test, n_lag, n_seq):\n",
    "    # extract raw values\n",
    "    raw_values = series.values\n",
    "    # transform data to be stationary\n",
    "    diff_series = difference(raw_values)\n",
    "    diff_values = diff_series.values\n",
    "    diff_values = diff_values.reshape(len(diff_values), 1)\n",
    "    # rescale values to -1, 1\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaled_values = scaler.fit_transform(diff_values)\n",
    "    scaled_values = scaled_values.reshape(len(scaled_values), 1)\n",
    "    # transform into supervised learning problem X, y\n",
    "    supervised = series_to_supervised(scaled_values, n_lag, n_seq)\n",
    "    supervised_values = supervised.values\n",
    "    # split into train and test sets\n",
    "    train, test = supervised_values[0:-n_test], supervised_values[-n_test:]\n",
    "    return scaler, train, test\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "    diff = []\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "    return Series(diff)\n",
    "\n",
    "# convert time series into supervised learning problem\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "# make a persistence forecast\n",
    "def persistence(last_ob, n_seq):\n",
    "    return [last_ob for i in np.arange(n_seq)]\n",
    " \n",
    "# evaluate the persistence model\n",
    "def make_forecasts(train, test, n_lag, n_seq):\n",
    "    forecasts = []\n",
    "    for i in range(len(test)):\n",
    "        X, y = test[i, 0:n_lag], test[i, n_lag:]\n",
    "        # make forecast\n",
    "        forecast = persistence(X[-1], n_seq)\n",
    "        # store the forecast\n",
    "        forecasts.append(forecast)\n",
    "    return forecasts\n",
    "\n",
    "# invert differenced forecast\n",
    "def inverse_difference(last_ob, forecast):\n",
    "    # invert first forecast\n",
    "    inverted = []\n",
    "    inverted.append(forecast[0] + last_ob)\n",
    "    # propagate difference forecast using inverted first value\n",
    "    for i in range(1, len(forecast)):\n",
    "        inverted.append(forecast[i] + inverted[i-1])\n",
    "    return inverted\n",
    "\n",
    "# inverse data transform on forecasts\n",
    "def inverse_transform(series, forecasts, scaler, n_test):\n",
    "    inverted = []\n",
    "    for i in range(len(forecasts)):\n",
    "        # create array from forecast\n",
    "        forecast = np.array(forecasts[i])\n",
    "        forecast = forecast.reshape(1, len(forecast))\n",
    "        # invert scaling\n",
    "        inv_scale = scaler.inverse_transform(forecast)\n",
    "        inv_scale = inv_scale[0, :]\n",
    "        # invert differencing\n",
    "        index = len(series) - n_test + i - 1\n",
    "        last_ob = series.values[index]\n",
    "        inv_diff = inverse_difference(last_ob, inv_scale)\n",
    "        # store\n",
    "        inverted.append(inv_diff)\n",
    "    return inverted\n",
    "\n",
    "# evaluate the RMSE for each forecast time step\n",
    "def evaluate_forecasts(test, forecasts, n_lag, n_seq):\n",
    "    for i in range(n_seq):\n",
    "        actual = test[(n_lag+i)]\n",
    "        predicted = [forecast[i] for forecast in forecasts]\n",
    "        rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "        print('t+%d RMSE: %f' % ((i+1), rmse))\n",
    "\n",
    "def main(raw_data,n_lag = 1,n_seq = 3,n_test = 2000,n_epochs = 1500, n_batch = 1, n_neurons = 1,sim=\"n\"):\n",
    "    \"\"\"\n",
    "    LSTM-AD - Long-Short term memory anomaly detection algorithm\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_lag :   comparison step into the past\n",
    "    n_seq : prediction step into the future\n",
    "    n_test : length of test series\n",
    "    n_epochs : number of epochs\n",
    "    n_batch : batch size (1 for time series datasets)\n",
    "    n_neurons : number of neurons in networks\n",
    "    sim : is this being run on simulated dataset with known anomalies?\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    # prepare data\n",
    "    scaler, train, test =  prepare_data(raw_data, n_test, n_lag, n_seq)\n",
    "    print(\"data prepared....\")\n",
    "    # make forecasts\n",
    "    forecasts = make_forecasts(train, test, n_lag, n_seq)\n",
    "    print(\"forecasts made....\")\n",
    "    # inverse transform forecasts and test\n",
    "    forecasts = inverse_transform(raw_data, forecasts, scaler, n_test+2)\n",
    "    print(\"forecasts inversed....\")\n",
    "        \n",
    "    #Evaluate predictions - scaled between 0-1\n",
    "    actual = [row[n_lag:] for row in test]\n",
    "    actual = inverse_transform(raw_data, actual, scaler, n_test+2)\n",
    "\n",
    "    actual2=np.reshape(actual,(n_test,n_seq))\n",
    "    forecasts2=np.reshape(forecasts,(n_test,n_seq))\n",
    "\n",
    "    # Compute comparison metric for predicted vs input (anomalies) [PICK CHANNEL] ######METHOD 1\n",
    "    metric = \"RMSE\"\n",
    "    out = evalPred.main(actual2[:,0], forecasts2[:,0], metric=metric)\n",
    "    print(\"predictions evaluated....\")\n",
    "\n",
    "    # Fit prediction error with Gaussian to extract anomaly score ####### METHOD 2\n",
    "    #pred = actual2[:,0]- forecasts2[:,0]\n",
    "    #anomaly_score = evalPred.GaussianPredError(pred ,thresh=0.05)  \n",
    "    #print(\"anomaly score generated....\")\n",
    "    \n",
    "    return out, forecasts2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     #Threshold metric before plotting\n",
    "#     thresh_min = 0\n",
    "#     thresh_max = 10000\n",
    "#     to_plot = out\n",
    "#     to_plot=np.asarray(to_plot)\n",
    "#     to_plot[to_plot<thresh_min]=0\n",
    "#     to_plot[to_plot>thresh_max]=thresh_max\n",
    "#     to_plot = to_plot/np.max(to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save NAB for various noise levels\n",
    "\n",
    "def LSTM_noise(max_noise=0.5, steps = 10):\n",
    "    \"\"\"\n",
    "    Model LSTM with varying simulated noise levels and plot output of detector score against time\n",
    "    \n",
    "    \"\"\"\n",
    "    NAB_noise = []\n",
    "    for n in np.linspace(0,max_noise,steps): # percentage of base signal amplitude\n",
    "        # create dataset\n",
    "        data, anomaly_loc, anomaly_dur, dates = sim.get_data(n,datalabels=[\"timestamp\",\"consumption\"])\n",
    "\n",
    "        # read csv\n",
    "        series = read_csv('sim_data.csv', header=0, index_col=0, squeeze=True)\n",
    "\n",
    "        # run LSTM\n",
    "        var = \"consumption\"\n",
    "        n_lag = 1\n",
    "        n_seq = 1\n",
    "        n_test = 2000\n",
    "        n_epochs = 1500\n",
    "        n_batch = 1\n",
    "        n_neurons = 1\n",
    "        # prepare data\n",
    "        scaler, train, test =  prepare_data(series[var], n_test, n_lag, n_seq)\n",
    "        # make forecasts\n",
    "        forecasts = make_forecasts(train, test, n_lag, n_seq)\n",
    "        # inverse transform forecasts and test\n",
    "        forecasts = inverse_transform(series, forecasts, scaler, n_test+2,var)\n",
    "\n",
    "        # reshape predictions and input\n",
    "        actual = [row[n_lag:] for row in test]\n",
    "        actual = inverse_transform(series, actual, scaler, n_test+2,var)\n",
    "        actual2=np.reshape(actual,(2000,1))\n",
    "        forecasts2=np.reshape(forecasts,(2000,1))\n",
    "\n",
    "        # Fit prediction error with Gaussian to extract anomaly score\n",
    "        pred = actual2[:,0]- forecasts2[:,0]\n",
    "        anomaly_score = evalPred.GaussianPredError(pred, anomaly_loc, anomaly_dur,thresh=0.05)\n",
    "\n",
    "        # Convert anomaly locations to binary array\n",
    "        labels = np.zeros_like(data)\n",
    "        for i in anomaly_loc:\n",
    "            labels[i] = 1\n",
    "\n",
    "        # Pad anomaly scores to zero during training\n",
    "        full_anomaly_scores = np.zeros_like(data)\n",
    "        full_anomaly_scores[8000:] = anomaly_score\n",
    "\n",
    "        # calculate NAB\n",
    "        NAB_noise.append(NAB.main(labels, full_anomaly_scores))\n",
    "    \n",
    "    x = np.linspace(0,0.5,10)*100\n",
    "    plt.plot(x, NAB_noise,'x')\n",
    "    plt.xlabel(\"Percentage noise\")\n",
    "    plt.ylabel(\"NAB score\")\n",
    "    #plt.xlim([0,25])\n",
    "    #plt.ylim([-1,100])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "468px",
    "left": "1394px",
    "right": "20px",
    "top": "144px",
    "width": "293px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
