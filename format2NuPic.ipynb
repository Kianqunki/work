{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install Obspy\n",
    "# https://github.com/obspy/obspy/wiki/Installation-on-Linux-via-Apt-Repository\n",
    "# with fix https://github.com/obspy/obspy/commit/f4ebf5a3d7c5f809901bb1dd31646b1f76872f47\n",
    "\n",
    "import pandas as pd\n",
    "import wave\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from obspy import read\n",
    "\n",
    "# Earthquake data http://geofon.gfz-potsdam.de/waveform/webservices.php\n",
    "# http://geofon.gfz-potsdam.de/fdsnws/dataselect/1/query?net=GE&sta=BKB&cha=BHZ&starttime=2011-03-11T06:00:00Z&endtime=2011-03-11T06:05:00Z\n",
    "# Requests 300 seconds of data from 0600 UTC on 11 March 2011, for the BHZ channel at GEOFON station Balikpapan, Kalimantan\n",
    "\n",
    "def main( FILE_PATH_,FILE_NAME_,values=None, typ=\"mseed\", output_type=\"HTM\",datalabels=[\"timestamp\",\"consumption\"]):\n",
    "    \"\"\"\n",
    "    Import datasets and convert into csv file as requested by Numenta (NUPIC)\n",
    "    \n",
    "    limit : downloaded earthquake file is very large - limit data points but include a earthquake\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    values : optional value imports simulated data\n",
    "    output_type : specify the format of the output file for NAB or HTM or other\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    OUTPUT_PATH_ = \"/home/codepan1/RestRunnerTestData/earthquake.csv\"\n",
    "    \n",
    "    \n",
    "    # File type search and onfigure\n",
    "    if typ == \"mseed\": # earthquake data\n",
    "        st = read(FILE_PATH_+FILE_NAME_)\n",
    "        data = st[0].data\n",
    "        info = st[0].stats\n",
    "    \n",
    "    elif typ == \"wav\": # sound wave data (Heart Beats)\n",
    "        st = pd.read_csv(FILE_PATH_+\"set_b.csv\") #list on wave names\n",
    "        spf = wave.open(FILE_PATH_+\"set_b/\" +\"Bunlabelledtest__101_1305030823364_A.wav\")\n",
    "\n",
    "        # Extract Raw Audio from Wav File\n",
    "        signal = spf.readframes(-1)\n",
    "        data = np.fromstring(signal, 'Int16')\n",
    "        \n",
    "    else: # simulated data\n",
    "        data = values\n",
    "\n",
    "    # Load data into dataframe\n",
    "    if output_type == \"NAB\":\n",
    "        columns = pd.MultiIndex.from_tuples(list(zip([\"timestamp\", \"value\"],[\"float\", \"float\"],[\"T\", \"\"])))\n",
    "        signal_df = np.array((np.arange(data.size), data)).T\n",
    "        signal_df = pd.DataFrame(signal_df, columns=columns)\n",
    "        signal_df.to_csv(OUTPUT_PATH_)\n",
    "    if output_type == \"HTM\":\n",
    "        dates = np.arange(len(data))\n",
    "        data_pd = pd.DataFrame(data=np.array((dates, list(data))).T, index=range(len(dates)),\n",
    "                       columns=[datalabels[0],datalabels[1]])\n",
    "        data_pd.to_csv(OUTPUT_PATH_ ,columns=[datalabels[0],datalabels[1]])\n",
    "    \n",
    "    return info\n",
    "#     plt.plot(data)\n",
    "#     plt.title(st[0].stats.starttime)\n",
    "#     plt.show()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE_PATH_ = \"/home/codepan1/Downloads/\"\n",
    "# FILE_NAME_ = \"fdsnws.mseed\"\n",
    "# limit = 20000000\n",
    "# st = read(FILE_PATH_+FILE_NAME_)\n",
    "# data = st[0].data[limit:]\n",
    "# tr = st[0] \n",
    "# st.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract datetime to time\n",
    "# dates = []\n",
    "# for t in tr.times():\n",
    "#     dates.append(tr.stats.starttime + t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Write to NUMENTA style csv file (Also for Numenta NAB)\n",
    "# \"\"\"\n",
    "\n",
    "# # Convert anomaly locations to binary array\n",
    "# labels = np.zeros_like(dates)\n",
    "# for i in anomaly_loc:\n",
    "#     labels[i] = 1\n",
    "    \n",
    "# # Pad anomaly scores to zero during training\n",
    "# full_anomaly_scores = np.zeros_like(dates)\n",
    "# full_anomaly_scores[8000:] = anomaly_score\n",
    "\n",
    "# # Write data to CSV file\n",
    "# datacsv = DataFrame()\n",
    "# datacsv[\"timestamp\"] = dates\n",
    "# datacsv[\"value\"] = np.round(data,3)\n",
    "# datacsv[\"anomaly_score\"] = full_anomaly_scores\n",
    "# datacsv[\"label\"] = labels\n",
    "\n",
    "# ## Write CSV to folder\n",
    "# #datacsv.to_csv(path_or_buf=\"/home/codepan1/RestRunnerCode/alpha_Twitter_volume_AAPL.csv\")\n",
    "# #series = read_csv(\"/home/codepan1/RestRunnerCode/alpha_Twitter_volume_AAPL.csv\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "617px",
    "left": "1402px",
    "right": "20px",
    "top": "174px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
